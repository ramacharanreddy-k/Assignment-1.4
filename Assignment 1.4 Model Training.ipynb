{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Follow the similar logic as Movie Classifer Demo done in the class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Tokenize text using spacy.\n",
        "- Download the Word2Vec Model\n",
        "- Vectorize all words in each review.\n",
        "- Calculate mean vector of the reviews\n",
        "- Train a Neural Network for classification\n",
        "- Test the trained neural network with few examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9fshIlu9R_Bi"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>horror</td>\n",
              "      <td>When six friends fly off on a weekend getaway...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>horror</td>\n",
              "      <td>The story is about a young girl who was touch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>romance</td>\n",
              "      <td>A young woman named Anna has always longed fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>horror</td>\n",
              "      <td>A London couple moves to a large country hous...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>horror</td>\n",
              "      <td>In a small college in North Carolina, only a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       genre                                        description\n",
              "0    horror    When six friends fly off on a weekend getaway...\n",
              "1    horror    The story is about a young girl who was touch...\n",
              "2   romance    A young woman named Anna has always longed fo...\n",
              "3    horror    A London couple moves to a large country hous...\n",
              "4    horror    In a small college in North Carolina, only a ..."
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('Data/data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>description</th>\n",
              "      <th>clean_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>horror</td>\n",
              "      <td>When six friends fly off on a weekend getaway...</td>\n",
              "      <td>when six friends fly off on a weekend getaway...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>horror</td>\n",
              "      <td>The story is about a young girl who was touch...</td>\n",
              "      <td>the story is about a young girl who was touch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>romance</td>\n",
              "      <td>A young woman named Anna has always longed fo...</td>\n",
              "      <td>a young woman named anna has always longed fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>horror</td>\n",
              "      <td>A London couple moves to a large country hous...</td>\n",
              "      <td>a london couple moves to a large country hous...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>horror</td>\n",
              "      <td>In a small college in North Carolina, only a ...</td>\n",
              "      <td>in a small college in north carolina only a s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       genre                                        description  \\\n",
              "0    horror    When six friends fly off on a weekend getaway...   \n",
              "1    horror    The story is about a young girl who was touch...   \n",
              "2   romance    A young woman named Anna has always longed fo...   \n",
              "3    horror    A London couple moves to a large country hous...   \n",
              "4    horror    In a small college in North Carolina, only a ...   \n",
              "\n",
              "                                   clean_description  \n",
              "0   when six friends fly off on a weekend getaway...  \n",
              "1   the story is about a young girl who was touch...  \n",
              "2   a young woman named anna has always longed fo...  \n",
              "3   a london couple moves to a large country hous...  \n",
              "4   in a small college in north carolina only a s...  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    # Convert to lowercase and remove punctuation\n",
        "    text = text.lower()\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "    return text\n",
        "df['clean_description'] = df['description'].apply(clean_text)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Genre counts:\n",
            "genre\n",
            "horror      672\n",
            "romance     672\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "genre_counts = df['genre'].value_counts()\n",
        "print(\"Genre counts:\")\n",
        "print(genre_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ramfeuji/Documents/Vettura AI/Week 1/Assignment 1.4/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>description</th>\n",
              "      <th>clean_description</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>horror</td>\n",
              "      <td>When six friends fly off on a weekend getaway...</td>\n",
              "      <td>when six friends fly off on a weekend getaway...</td>\n",
              "      <td>[friends, fly, weekend, getaway, suddenly, pla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>horror</td>\n",
              "      <td>The story is about a young girl who was touch...</td>\n",
              "      <td>the story is about a young girl who was touch...</td>\n",
              "      <td>[story, young, girl, touch, spirit, caused, de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>romance</td>\n",
              "      <td>A young woman named Anna has always longed fo...</td>\n",
              "      <td>a young woman named anna has always longed fo...</td>\n",
              "      <td>[young, woman, named, anna, longed, love, fail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>horror</td>\n",
              "      <td>A London couple moves to a large country hous...</td>\n",
              "      <td>a london couple moves to a large country hous...</td>\n",
              "      <td>[london, couple, moves, large, country, house,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>horror</td>\n",
              "      <td>In a small college in North Carolina, only a ...</td>\n",
              "      <td>in a small college in north carolina only a s...</td>\n",
              "      <td>[small, college, north, carolina, select, stud...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       genre                                        description  \\\n",
              "0    horror    When six friends fly off on a weekend getaway...   \n",
              "1    horror    The story is about a young girl who was touch...   \n",
              "2   romance    A young woman named Anna has always longed fo...   \n",
              "3    horror    A London couple moves to a large country hous...   \n",
              "4    horror    In a small college in North Carolina, only a ...   \n",
              "\n",
              "                                   clean_description  \\\n",
              "0   when six friends fly off on a weekend getaway...   \n",
              "1   the story is about a young girl who was touch...   \n",
              "2   a young woman named anna has always longed fo...   \n",
              "3   a london couple moves to a large country hous...   \n",
              "4   in a small college in north carolina only a s...   \n",
              "\n",
              "                                      tokenized_text  \n",
              "0  [friends, fly, weekend, getaway, suddenly, pla...  \n",
              "1  [story, young, girl, touch, spirit, caused, de...  \n",
              "2  [young, woman, named, anna, longed, love, fail...  \n",
              "3  [london, couple, moves, large, country, house,...  \n",
              "4  [small, college, north, carolina, select, stud...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "def spacy_tokenizer(text):\n",
        "    doc = nlp(clean_text(text))\n",
        "    # Remove stop words and keep only meaningful tokens\n",
        "    tokens = [token.text for token in doc if not token.is_stop and not token.is_space and len(token.text) > 1]\n",
        "    return tokens\n",
        "\n",
        "# Apply tokenizer to the 'cleaned_description' column\n",
        "df['tokenized_text'] = df['clean_description'].apply(spacy_tokenizer)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df['tokenized_text'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zk/ls5wtq6s1s9c89z165cvqslm0000gq/T/ipykernel_68450/4165584456.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
            "  review_word_vectors.append(torch.FloatTensor(vectors))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique classes: 2\n",
            "Classes: [' horror ' ' romance ']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "vector_size = 100  # Define embedding size\n",
        "\n",
        "# Ensure tokenized_text column is a list of lists\n",
        "df['tokenized_text'] = df['tokenized_text'].apply(lambda x: x if isinstance(x, list) else [])\n",
        "\n",
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=df['tokenized_text'].tolist(), vector_size=vector_size, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Convert tokens to vectors\n",
        "review_word_vectors = []\n",
        "sequence_lengths = []\n",
        "\n",
        "for tokens in df['tokenized_text']:\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        if token in word2vec_model.wv:\n",
        "            vectors.append(word2vec_model.wv[token])\n",
        "        else:\n",
        "            vectors.append(np.zeros(vector_size))\n",
        "    \n",
        "    if not vectors:  # Handle empty sequences\n",
        "        vectors.append(np.zeros(vector_size)) \n",
        "    \n",
        "    sequence_lengths.append(len(vectors))\n",
        "    review_word_vectors.append(torch.FloatTensor(vectors))\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(df['genre'])\n",
        "\n",
        "# Pad sequences in batch\n",
        "X = pad_sequence(review_word_vectors, batch_first=True)\n",
        "y = torch.LongTensor(encoded_labels)\n",
        "\n",
        "print(\"Number of unique classes:\", len(label_encoder.classes_))\n",
        "print(\"Classes:\", label_encoder.classes_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImprovedTextClassifier(nn.Module):\n",
        "    def __init__(self, input_size=100, hidden_size=128, num_classes=2):\n",
        "        super(ImprovedTextClassifier, self).__init__()\n",
        "        \n",
        "        # Add dropout for regularization\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # Bi-directional LSTM layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=2, \n",
        "                           batch_first=True, bidirectional=True, dropout=0.2)\n",
        "        \n",
        "        # Attention mechanism\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "        \n",
        "        # Output layers with batch normalization\n",
        "        self.bn = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x, lengths):\n",
        "        # Apply initial dropout\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        # Pack padded sequence for LSTM\n",
        "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
        "        packed_output, _ = self.lstm(packed_input)\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "        \n",
        "        # Apply attention\n",
        "        attention_weights = self.attention(output)\n",
        "        context = torch.sum(attention_weights * output, dim=1)\n",
        "        \n",
        "        # Apply batch normalization and final layers\n",
        "        context = self.bn(context)\n",
        "        x = torch.relu(self.fc1(context))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_idx, temp_idx = train_test_split(range(len(y)), test_size=0.3, random_state=42, stratify=y)\n",
        "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42, stratify=y[temp_idx])\n",
        "\n",
        "# Split data\n",
        "X_train, y_train = X[train_idx], y[train_idx]\n",
        "X_val, y_val = X[val_idx], y[val_idx]\n",
        "X_test, y_test = X[test_idx], y[test_idx]\n",
        "\n",
        "train_lengths = [sequence_lengths[i] for i in train_idx]\n",
        "val_lengths = [sequence_lengths[i] for i in val_idx]\n",
        "test_lengths = [sequence_lengths[i] for i in test_idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30:\n",
            "Training Loss: 0.7388\n",
            "Validation Loss: 0.6935, Accuracy: 0.5000\n",
            "Epoch 2/30:\n",
            "Training Loss: 0.7123\n",
            "Validation Loss: 0.6903, Accuracy: 0.5248\n",
            "Epoch 3/30:\n",
            "Training Loss: 0.6627\n",
            "Validation Loss: 0.5966, Accuracy: 0.7327\n",
            "Epoch 4/30:\n",
            "Training Loss: 0.6181\n",
            "Validation Loss: 0.5984, Accuracy: 0.7277\n",
            "Epoch 5/30:\n",
            "Training Loss: 0.6161\n",
            "Validation Loss: 0.5499, Accuracy: 0.7772\n",
            "Epoch 6/30:\n",
            "Training Loss: 0.6021\n",
            "Validation Loss: 0.6196, Accuracy: 0.7426\n",
            "Epoch 7/30:\n",
            "Training Loss: 0.6047\n",
            "Validation Loss: 0.5533, Accuracy: 0.7624\n",
            "Epoch 8/30:\n",
            "Training Loss: 0.5897\n",
            "Validation Loss: 0.4999, Accuracy: 0.7772\n",
            "Epoch 9/30:\n",
            "Training Loss: 0.5721\n",
            "Validation Loss: 0.5176, Accuracy: 0.7871\n",
            "Epoch 10/30:\n",
            "Training Loss: 0.5751\n",
            "Validation Loss: 0.5697, Accuracy: 0.7871\n",
            "Epoch 11/30:\n",
            "Training Loss: 0.5682\n",
            "Validation Loss: 0.5438, Accuracy: 0.7871\n",
            "Epoch 12/30:\n",
            "Training Loss: 0.5529\n",
            "Validation Loss: 0.7104, Accuracy: 0.6931\n",
            "Epoch 13/30:\n",
            "Training Loss: 0.5661\n",
            "Validation Loss: 0.5106, Accuracy: 0.7723\n",
            "Early stopping triggered\n",
            "\n",
            "Test Results:\n",
            "Test Loss: 0.5263\n",
            "Test Accuracy: 0.7574\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     horror        0.74      0.80      0.77       101\n",
            "    romance        0.78      0.71      0.75       101\n",
            "\n",
            "    accuracy                           0.76       202\n",
            "   macro avg       0.76      0.76      0.76       202\n",
            "weighted avg       0.76      0.76      0.76       202\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler  # Add this import\n",
        "\n",
        "# Initialize model and training components\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ImprovedTextClassifier(input_size=vector_size, hidden_size=128, num_classes=2).to(device)\n",
        "\n",
        "# Simple cross entropy loss without weights\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer with weight decay\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "\n",
        "# Learning rate scheduler - fixed import\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "\n",
        "# Training batch function\n",
        "def train_batch(X_batch, y_batch, lengths_batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    \n",
        "    outputs = model(X_batch, lengths_batch)\n",
        "    loss = criterion(outputs, y_batch)\n",
        "    \n",
        "    loss.backward()\n",
        "    # Gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss.item()\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(X_data, y_data, lengths_data):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(X_data), batch_size):\n",
        "            batch_X = X_data[i:i+batch_size].to(device)\n",
        "            batch_y = y_data[i:i+batch_size].to(device)\n",
        "            batch_lengths = lengths_data[i:i+batch_size]\n",
        "            \n",
        "            outputs = model(batch_X, batch_lengths)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "    \n",
        "    return total_loss / (len(X_data) // batch_size + 1), np.array(predictions)\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 30\n",
        "batch_size = 32\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    # Shuffle training data\n",
        "    indices = torch.randperm(len(X_train))\n",
        "    \n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        batch_indices = indices[i:i+batch_size]\n",
        "        batch_X = X_train[batch_indices]\n",
        "        batch_y = y_train[batch_indices]\n",
        "        batch_lengths = [train_lengths[j] for j in batch_indices]\n",
        "        \n",
        "        loss = train_batch(batch_X, batch_y, batch_lengths)\n",
        "        total_loss += loss\n",
        "    \n",
        "    # Validation phase\n",
        "    val_loss, val_predictions = evaluate(X_val, y_val, val_lengths)\n",
        "    val_accuracy = (val_predictions == y_val.numpy()).mean()\n",
        "    \n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "    print(f'Training Loss: {total_loss/(len(X_train)//batch_size):.4f}')\n",
        "    print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
        "    \n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # Early stopping check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # Save best model\n",
        "        torch.save(model.state_dict(), 'best_model.pth', _use_new_zipfile_serialization=True)\n",
        "\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print('Early stopping triggered')\n",
        "            break\n",
        "\n",
        "# Load best model for testing\n",
        "model.load_state_dict(torch.load('best_model.pth', weights_only=True, map_location=device))\n",
        "\n",
        "# Final evaluation on test set\n",
        "test_loss, test_predictions = evaluate(X_test, y_test, test_lengths)\n",
        "test_accuracy = (test_predictions == y_test.numpy()).mean()\n",
        "\n",
        "print(f'\\nTest Results:')\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Print detailed classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_test.numpy(), test_predictions, \n",
        "                          target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_example(text, model, word2vec_model, device):\n",
        "    # Process text with spaCy\n",
        "    doc = nlp(text)\n",
        "    token_list = [token.text for token in doc if not token.is_space]\n",
        "    \n",
        "    # Vectorize each word\n",
        "    vectors = []\n",
        "    for token in token_list:\n",
        "        if token in word2vec_model.wv:\n",
        "            vectors.append(word2vec_model.wv[token])\n",
        "        else:\n",
        "            # Use mean vector instead of zeros for unknown words\n",
        "            vectors.append(word2vec_model.wv.vectors.mean(axis=0))\n",
        "    \n",
        "    if not vectors:\n",
        "        vectors.append(np.zeros(vector_size))\n",
        "    \n",
        "    # Convert to tensor and move to device\n",
        "    input_tensor = torch.FloatTensor(vectors).unsqueeze(0).to(device)\n",
        "    sequence_length = [len(vectors)]\n",
        "    \n",
        "    # Model prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor, sequence_length)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        confidence, predicted = torch.max(probabilities, 1)\n",
        "        \n",
        "        # Get prediction and confidence\n",
        "        predicted_genre = label_encoder.inverse_transform(predicted.cpu().numpy())\n",
        "        confidence_score = confidence.item()\n",
        "    \n",
        "    return predicted_genre[0], confidence_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted genre for horror_text1: (' horror ', 0.6898594498634338)\n",
            "Predicted genre for horror_text2: (' horror ', 0.6314055323600769)\n",
            "Predicted genre for romance_text1: (' romance ', 0.9601119756698608)\n",
            "Predicted genre for romance_text2: (' romance ', 0.9418725371360779)\n"
          ]
        }
      ],
      "source": [
        "horror_text1 = \"In a remote mountain cabin, Sarah discovers an ancient diary that speaks of a malevolent entity lurking in the surrounding woods. As winter storms trap her inside, she begins experiencing terrifying visions and mysterious scratching sounds from within the walls. Each night, the scratching gets closer to her bedroom. The diary reveals a dark history of disappearances spanning centuries, all occurring during the winter solstice - which is just days away. Sarah notices shadowy figures in her peripheral vision and finds strange symbols carved into the cabin's foundation. The local townspeople refuse to speak about the cabin's history, crossing themselves whenever it's mentioned. As the solstice approaches, Sarah uncovers the horrifying truth: the cabin itself is a gateway, and something ancient and hungry is preparing to cross through. With no escape possible, she must unravel the cabin's secrets before she becomes its next victim.\"\n",
        "horror_text2 = \"Deep beneath the city, a team of urban explorers stumbles upon a network of forgotten Victorian-era tunnels. The discovery seems like an urban explorer's dream until they find disturbing evidence of recent activity - fresh scratch marks on the walls, discarded modern clothing covered in dark stains, and strange symbols painted in what appears to be blood. Their helmet cameras capture glimpses of something moving in the darkness, something that doesn't look entirely human. The deeper they venture, the more they realize they're not alone. The tunnels seem to shift and change behind them, cutting off their escape routes. Their lights begin to fail one by one, and the air grows thick with the scent of decay. The team's excitement turns to terror as they realize they've awakened something that has been waiting in the darkness for over a century. The scratching sounds growing closer are just the beginning.\"\n",
        "romance_text1 = \"Emma returns to her coastal hometown to sell her late grandmother's flower shop, expecting to stay only a few weeks. But when she runs into her high school sweetheart, Oliver, now a marine biologist studying local tide pools, old feelings begin to resurface. As they work together to save the shop's historic garden from being demolished for a new development, they rediscover their shared love of nature and each other. During late nights restoring the garden's century-old greenhouse, they slowly open up about their paths not taken and dreams deferred. Oliver shows Emma the magic of bioluminescent waves and hidden tidal caves, while she helps him see the beauty in putting down roots. With the garden's spring fundraiser approaching, they must decide if their rekindled connection is strong enough to withstand the forces pulling them in different directions.\"\n",
        "romance_text2 = \"Chef Sofia's carefully ordered life in Manhattan is thrown into chaos when a charming food critic, James, gives her innovative restaurant a mixed review. Determined to prove him wrong, she challenges him to spend a week cooking alongside her in the kitchen. As they work elbow to elbow creating new dishes, their initial antagonism gives way to mutual respect and attraction. James helps Sofia rediscover the joy of cooking without pretense, while she shows him the passion and artistry behind every dish she creates. During long nights perfecting recipes and early morning visits to farmers' markets, they find themselves sharing more than just cooking techniques. But when a prestigious opportunity in Paris threatens to separate them, they must decide what matters most: their careers or their growing love for each other.\"\n",
        "\n",
        "print(\"Predicted genre for horror_text1:\", predict_example(horror_text1, model, word2vec_model, device))\n",
        "print(\"Predicted genre for horror_text2:\", predict_example(horror_text2, model, word2vec_model, device))\n",
        "print(\"Predicted genre for romance_text1:\", predict_example(romance_text1, model, word2vec_model, device))\n",
        "print(\"Predicted genre for romance_text2:\", predict_example(romance_text2, model, word2vec_model, device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "def save_model_components(model, word2vec_model, label_encoder, save_dir='model_files'):\n",
        "    \n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    \n",
        "    # Save the PyTorch model\n",
        "    torch.save(model.state_dict(), \n",
        "              os.path.join(save_dir, 'model.pth'), \n",
        "              _use_new_zipfile_serialization=True)\n",
        "    \n",
        "    # Save the Word2Vec model\n",
        "    word2vec_model.save(os.path.join(save_dir, 'word2vec.model'))\n",
        "    \n",
        "    # Save the label encoder\n",
        "    joblib.dump(label_encoder, os.path.join(save_dir, 'label_encoder.joblib'))\n",
        "    \n",
        "    # Save model configuration (if needed)\n",
        "    model_config = {\n",
        "        'input_size': vector_size,\n",
        "        'hidden_size': 128,\n",
        "        'num_classes': 2\n",
        "    }\n",
        "    joblib.dump(model_config, os.path.join(save_dir, 'model_config.joblib'))\n",
        "\n",
        "# Call this after training\n",
        "save_model_components(model, word2vec_model, label_encoder)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
